---
title: "Getting started with the scRNAutils package"
author: "Jose Verdezoto Mosquera"
date:  "`r Sys.Date()`"
output:
  BiocStyle::html_document:
    toc: true
vignette: >
  %\VignetteIndexEntry{1. Getting started with the scRNAutils package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r echo=FALSE}
# These settings make the vignette prettier
knitr::opts_chunk$set(results="hold", collapse = FALSE, message=FALSE, 
                      warning = FALSE)
```

# Introduction to the Miller lab scRNAutils package 

The main goal of this tutorial is to show usage of the scRNA-seq processing pipeline included in the `scRNAutils` package. This analysis pipeline was used to process individual raw libraries for the Human atherosclerosis scRNA-meta-analysis project and will be used to streamline addition of new datasets into future iterations of the meta-analyzed dataset. This package is meant to be a comprehensive complement to gold-standard normalization and dimensionality reduction functions implemented in Seurat. 

We've decided to encapsulate the pipeline within an R package instead of a more typical pipeline workflow as this give us the flexibility to include other handy functions for data analysis, manipulation and visualization. We hope this pipeline and other current (and upcoming) functions will help people without extensive programming experience to process their own data. The package continues undergoing future improvements and integration of new features. 


## Installing scRNAutils and required dependencies 

Here are some important dependencies that need to be installed for the package to work:

```{r, eval=FALSE}

# Make sure the Bioconductor package manager is installed. 
# If not, install with the following line of code
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("Biocmanager")

# This function will check whether dependencies are installed. 
# If they're not, it'll install them either from CRAN or Bioconductor.
checkDeps = function(p, bioc=FALSE) {
  if (! p %in% installed.packages()) {
    if (bioc) { 
      BiocManager::install(pkgs = p)
    } else {
      install.packages(p)
    }
  }
}

# Run the function to confirm installation of essential packages
checkDeps("Seurat")
checkDeps("glmGamPoi", bioc=TRUE)
checkDeps("scDblFinder", bioc=TRUE)
checkDeps("scater", bioc=TRUE)
checkDeps("sctransform")
checkDeps("SingleCellExperiment", bioc=TRUE)
checkDeps("celda", bioc=TRUE)
checkDeps("tidyverse")
checkDeps("reticulate")
checkDeps("cluster")
checkDeps("stats")
checkDeps("data.table")
checkDeps("ggsci")
checkDeps("ggpubr")

# Other dependencies can be installed directly from Github
devtools::install_github("cellgeni/sceasy")

```

The package can be directly installed from Github as follows: 

```{r, eval=FALSE}

devtools::install_github("MillerLab-CPHG/scRNAutils")

```

Load all of the required packages into the R session:

```{r, message=FALSE, results="hide", warning=FALSE}

deps = c("Seurat", "scater", "glmGamPoi", "scDblFinder", "sceasy", "SingleCellExperiment", "celda", "tidyverse", "cluster", "broom", "stats", "data.table", "ggsci", "ggpubr")
lapply(deps, library, character.only=TRUE)

```

## Overview of the pipeline and loading of example data

The pipeline, as currently written, is a single function that takes care of the QC, normalization, dimensionality reduction and clustering optimization. Broadly this is the implemented workflow:

  1. **QC** Create a Seurat object and do one round of `louvain` clustering to get clusters needed for artificial doublet generation with `scDblFinder`. 
  2. Remove doublets by performing `n` number of doublet identification iterations (default is `n=3 iterations` but can be any number defined by the user). I wouldn't recommend going more than 10 iterations, especially for larger libraries. 
  3. Once doublets have been removed, we use our own `decontX` wrapper to remove ambient RNA. This wrapper takes a Seurat object as input and returns a Seurat object with cleaned raw counts within the `RNA assay`.
  4. This iteration offers the option to perform adaptive thresholding for QC. This filtering is based on the Median Basolute Deviation (MAD), which is a metric of varriance more robust to outliers than the mean and standard deviation (sd). Adaptive thresholding is a more flexible alternative than harcoding thresholds, especially if dealing with libraries with a wide range of complexity (e.g., sequencing depth) and is set as the default filtering. However, we also allow the user to hard code thresholds for number of reads/UMIs, unique genes expressed and percentage of reads mapped to mithochondrial/hemoglobin genes (cells with large portion of reads mapping to Hb genes might represent contaminating erythrocytes). This will be the last stage of QC. 
  5. **Normalization** After QC, data will be normalized using the `SCTransform` algorithm developed by **Hafemeister et al., 2019**.
  6. After rigorous testing, we have found that MALAT1, Mitochondrial- and Ribosomal-related genes are the most highly expressed features in 10x and Smart-seq2 datasets. Therefore, we offer an optional step to remove these genes from the set of highly variable features (HVGs) used for dimensionality reduction.
  6. **Dimensionality reduction** is done with PCA and UMAP. This new iteration of the pipeline includes an optimization step to find the number of PCs that explain 90% of the variance in the data. 
  7. **Clustering optimization** This step leverages user-provided minimum and maximum values of clustering resolutions to calculate average silhouette scores for each of them.
  8. The pipeline then selects the clustering resolution with the *maximum average silhouette score* and perform Louvain (leiden will be implemented soon) clustering to get the final set of clusters.

The pipeline outputs several plots and stats that allow the user to get an overview of the effect of the QC in the data. This will be explained in more detail below. Additionally, we offer the user the option to convert the processed Seurat object into Anndata (`.h5ad`) format, which can then be loaded into Python compatible processing/modeling frameworks such as `scanpy` and `scvitools` 

The pipeline currently takes a genes x cells count matrix as input. The count matrix needs to be in `sparse` or `dgCMatrix` format. This is required by the user but we might eventually handle conversion to sparse matrix format inside of the function. We'll showcase the pipeline using a library from *Hu et al. ATBV, 2021*

``` {r}

# Load the package
library(scRNAutils)

# Load example library from Hu et al., 2021
coronary2 = Seurat::Read10X("/scratch/jev4xy/MetaPlaq/v2/raw_scRNA_data/Hu_et_al_human_coronaries_aortas_pulmonary/cardiac_arteries_processed_data/patient2_CA2/")

# Check we have the right input
paste0("The provided input is a", class(coronary2))

```

# Run the pipeline and explore its outputs

## Process data with `doItAll()`

The entire pipeline can be run using the `doItAll()` function. We just need to specify some arguments. Description of the arguments can be found upon loading the package. But here's a brief overview:

   - `countsMatrix`: A matrix in `sparse` or `dgCMatrix` format where rows are genes and columns are cells **(required)**. 
   - `studyID`, `libraryID`, `tissueSource` and `seqPlatform`: These are character strings that will add corresponding metadata into the processed Seurat object. These are **required** arguments. 
   - `nMADs`: Number of MADs used for outlier-detection. Using adaptive thresholding assumes that most of the cells in the data are of good quality. Make sure to use only with a raw counts matrix that has not been previously pre-filtered. By default we use a nMAD = 1, which is highly conservative but you can set this number to whatever you'd like. 
   - `UMI`: A boolean that indicates whether the input assay relies on UMIs. 
   - `minRes` and `maxRes`: These are numeric values indicating the lower and upper boundaries of clustering resolutions for calculating silhouette coefficients **(default=0.3 and 1.9)**. These values should be adjusted depending on the number of cells per library. 
   - `dblRemoveIter`: A numeric value defining the number of iterations performed to get consensus doublet barcodes **(default=3)**.
   - `queryFeatures`: A character vector with the names of genes to check their expression before and after QC **(optional)**. 
   - `makeAnnData`: A boolean that determines whether the processed Seurat object should be converted to `.h5ad` format. The `annDataParentDir` determines the directory the Anndata object will be written to. 

```{r, message=FALSE, results="hide", warning=FALSE}

# Define genes of interest
genesVec = c("MYH11", "CNN1", "LTBP1", "TNFRSF11B")

# Run pipeline
HuPipelineOuts = scRNAutils::doItAll(
  countsMatrix = coronary2, 
  studyID = "Hu_et_al", 
  libraryID = "Hu_coronary2_p2",
  tissueSource = "coronary",
  seqPlatform = "10x",
  nMADs = 1,
  UMI = TRUE, 
  minRes = 0.4, 
  maxRes = 1,
  dblFindIter = 3,
  queryFeatures = genesVec,
  makeAnnData = TRUE,
  annDataParentDir = "/scratch/jev4xy/"
  )


```

The pipeline output consists of a list with 6 items:

  - The processed `Seurat object`.
  - Consensus doublet cell barcodes identified by n iterations defined by the user. 
  - UMAP of clusters before QC.
  - UMAP of clusters after QC.
  - Gene expression UMAPs before QC, including genes defined by the user in the `genes_of_interest` argument.
  - Gene expression UMAPs after QC, including genes defined by the user in the `genes_of_interest` argument.

```{r}

# Check items produced by the pipeline
names(HuPipelineOuts)

```

## Explore some QC stats and plots

We can start by looking at the effect of MAD-based outlier detection. In addition to the number of reads/genes and % reads mapped to mitochondrial-related genes, we also look at the % of reads mapped to ribosomal and hemoglobin genes.

```{r, fig.cap="Key metrics before QC"}

preQCmetrics = HuPipelineOuts$preQCstats$metricsPlot
preQCmetrics

```

And contamination scores:

```{r}

HuPipelineOuts$preQCstats$contaminationScores

```

The same metrics after QC:

```{r, fig.cap="Key metrics after MAD-based QC"}

postQCmetrics = HuPipelineOuts$postQCstats$metricsPlot
postQCmetrics

```

Since we QC cells based on joint QC metrics instead of individually filtering based on nReads/Genes or %MT separately, we also show library complexity before and after QC

```{r, fig.cap="Library complexity before QC"}

preComplexity = HuPipelineOuts$preQCstats$libraryComplexity
suppressWarnings(preComplexity)

```

This shows the importance of filtering cells based on joint metrics. We can see that cells with the highest % of reads mapped to MT-related genes are also those with the lowest number of UMIs and genes. We can check the effect of MAD-based filtering on the library complexity. 

```{r, fig.cap="Library complexity post QC"}

postComplexity = HuPipelineOuts$postQCstats$libraryComplexity
postComplexity

```

library complexity can also be displayed as a histogram, where we expect high quality cells to have complexity scores > 0.8

```{r, fig.cap="Library complexity histogram"}

HuPipelineOuts$postQCstats$complexityHist

```



We can also get summary stats of key QC metrics:

```{r, fig.cap="Summary stats of key QC metrics before filtering"}

HuPipelineOuts$preQCstats$metricsSummary

```

After cell filtering:

```{r, fig.cap="Summary stats of key QC metrics after filtering"}

HuPipelineOuts$postQCstats$metricsSummary

```

## Explore clustering results
  
We can explore clustering results as follows:

```{r, fig.cap="Clusters before and after QC", fig.align="center" }

# Plot cluster UMAPs comparing data before and after QC
preQCclusters = HuPipelineOuts$preQCclusters + ggtitle ("Clusters before QC") + 
  theme(legend.position = "none") + 
  custom_theme() 

postQCclusters = HuPipelineOuts$postQCclusters + ggtitle("Clusters after QC") + 
  theme(legend.position = "none") + 
  custom_theme() 

# Plot UMAPS together
cowplot::plot_grid(preQCclusters, postQCclusters)

```

## Explore gene expression results

We can also take a look at how gene expression looks before removing ambient RNA:

```{r, fig.cap="Gene expression for user defined genes before QC", fig.align="center"}

# Extract gene expression UMAPs from the pipeline output
preQCfeatureList = HuPipelineOuts$preQCfeatures 
postQCfeatureList = HuPipelineOuts$postQCfeatures 

# Plot gene expression before QC
cowplot::plot_grid(plotlist = preQCfeatureList, 
                   ncol=2)

```

Now let's take a look at how gene expression looks after removing ambient RNA: 

```{r, fig.cap="Gene expression for user defined genes before QC", fig.align="center"}

cowplot::plot_grid(plotlist=postQCfeatureList, 
                   ncol=2)

```

We can notice the effect of QC by looking at genes such as TNFRSF11B, which is known to be highly specific to SMC-derived fibromyocytes. Removal of ambient RNA contamination shows that TNFRSF11B is specific to the SMC cluster, as we expect. 

Finally, we can see which genes are the most highly expressed in the dataset with the following function:

```{r, fig.cap="N most highly expressed genes in the dataset"}

seu = HuPipelineOuts$seuratObj
plotTopAvgExpr(seuratObj = seu, makeBoxplot = TRUE, nGenes = 20)

```


If you want to check whether you need to relax QC filters, you can check the number of cells before and after QC withthe following:

```{r}

HuPipelineOuts$postQCstats$cellNumber

```


## Explore functions for downstream analyses

Here we'll showcase one of the functions included in the package. Let's say we just cleaned our data and we have a Seurat object. Now we're itching to see how our gene of interest (e.g., FN1) correlates to other genes in our SMC clusters. This can be easily achieved with only a few lines of code. We simply need to provide the input seurat object as well as the name of the metadata column that has the cluster/cell type IDs we're insterested in. 

```{r, fig.cap="Comparison of FN1 and VCAN expression in SMCs", fig.align="center"}

# Plot correlations between two genes in SMCs
plot2GeneCor(
  seuratObj =  HuPipelineOuts$seuratObj,
  targetColData = c("seurat_clusters"),
  targetAnno = c(2, 1, 5),
  targetGenes = c("FN1", "VCAN"),
  showCor = FALSE
  )

```

If we wish to fit a linear model and to calculate a correlation coefficient for the two input genes in SMCs, we just need to set `show_cor=TRUE` and define the type of correlation coefficient (either `pearson` or `spearman`).

```{r, fig.cap="Pearson correlation between FN1 and VCAN expression in SMCs", fig.align="center"}

# Fit linear model and calculate pearson cor coeff
plot2GeneCor(
  seuratObj =  HuPipelineOuts$seuratObj,
  targetColData = c("seurat_clusters"),
  targetAnno = c(2, 1, 5),
  targetGenes = c("FN1", "VCAN"),
  showCor = TRUE,
  corMethod = "pearson"
  )

```


# Conclusion

That's it for now. As previously mentioned, the pipeline continues undergoing improvement, it does what I think are the essential processing steps for any scRNA library. Some other features we're currently trying to add include:
  - Addition of Leiden clustering as an alternative to Louvain. 
  - Addition of alternative algorithms to optimize clustering resolution. 

